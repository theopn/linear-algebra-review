%! TEX root = ../ma351.tex

\section{Definition of the Determinant}

\begin{itemize}
  \item For a $2 \times 2$ matrix,
    \begin{align*}
      \begin{bmatrix}
        a & b\\
        c & d
      \end{bmatrix}^{-1} = \frac{1}{ad - cb}
      \begin{bmatrix}
        d & -b\\
        -c & a
      \end{bmatrix}
    \end{align*}
    The factor $\delta = ad - cb$ is called \textbf{determinant}.
    \begin{align*}
      det \begin{bmatrix}
        a & b\\
        c & d
      \end{bmatrix} = \begin{vmatrix}
        a & b\\
        c & d
      \end{vmatrix} = ad - bc
    \end{align*}
  \item \textbf{Laplace Expansion} or \textbf{Cofactor Expansion} states that the determinant of any $n \times n$ matrix can be obtained using using determinants of $(n - 1) \times (n - 1)$ submatrices.
    Specifically, for every $i$,
    \begin{align*}
      det(A) &= \sum_{j=1}^{n} (-1)^{i + j} a_{ij} A_{ij}
    \end{align*}
    \noindent Where $a_{ij}$ is the entry of $i$th row and $j$th column and $A_{ij}$ is the determinant of the submatrix obtained by removing the $i$th row and $j$th column.
  \item We can use Laplace Expansion to find the determinant of $3 \times 3$ matrix. Choosing $i = 1$,
    \begin{align*}
      \begin{vmatrix}
        a & b & c\\
        d & e & f\\
        g & h & i
      \end{vmatrix}
      &=
      a \cdot \begin{vmatrix}
        \text{\sout{a}} & \text{\sout{b}} & \text{\sout{c}}\\
        \text{\sout{d}} & e & f\\
        \text{\sout{g}} & h & i
      \end{vmatrix}
      - b \cdot \begin{vmatrix}
        \text{\sout{a}} & \text{\sout{b}} & \text{\sout{c}}\\
        d & \text{\sout{e}} & f\\
        g & \text{\sout{h}} & i
      \end{vmatrix}
      + c \cdot \begin{vmatrix}
        \text{\sout{a}} & \text{\sout{b}} & \text{\sout{c}}\\
        d & e & \text{\sout{f}}\\
        g & h & \text{\sout{i}}
      \end{vmatrix}\\
      &= a(ei - fh) - b(di - fg) + c(dh - eg)\\
      &= aei + bfg + cdh - ceg - bdi - afh
    \end{align*}
    Choosing $i = 2$ yields the same result
    \begin{align*}
      \begin{vmatrix}
        a & b & c\\
        d & e & f\\
        g & h & i
      \end{vmatrix}
      &=
      - d \cdot \begin{vmatrix}
        \text{\sout{a}} & b & c\\
        \text{\sout{d}} & \text{\sout{e}} & \text{\sout{f}}\\
        \text{\sout{g}} & h & i
      \end{vmatrix}
      + e \cdot \begin{vmatrix}
        a & \text{\sout{b}} & c\\
        \text{\sout{d}} & \text{\sout{e}} & \text{\sout{f}}\\
        g & \text{\sout{h}} & i
      \end{vmatrix}
      - f \cdot \begin{vmatrix}
        a & b & \text{\sout{c}}\\
        \text{\sout{d}} & \text{\sout{e}} & \text{\sout{f}}\\
        g & h & \text{\sout{i}}
      \end{vmatrix}\\
      &= -d(bi - ch) + e(ai - cg) - f(ah - bg)\\
      &= -bdi + cdh + aei - ceg - afh + bfg\\
      &= aei + bfg + cdh - ceg - bdi - afh
    \end{align*}
    Focus on the signs since the values of $(-1)^{i + j}$ differ when we chose to fix $i = 1$ versus $i = 2$.\\
    Also, you can change the $i$ and $j$ in the summation and the equation still holds since the determinants of $A$ and $A^{t}$ are identical.
  \item \textbf{Row Interchange Property}: Let $A$ be an $n \times n$ matrix and supposed $B$ is obtained by interchanging two rows of $A$.
    Then $\mathrm{det} B = - \mathrm{det} A$
  \item \textbf{Row Scalar Property}: Supposed the $n \times n$ matrix $B$ is obtained from $A$ by multiplying each element in the $i$th row by some scalar $c$.
    Then $\mathrm{det} B = c \mathrm{det} A$
  \item \textbf{Row Additive Property}: Let $U$, $V$, and $A_i$ be $1 \times n$ row matrices, where $i = 2, 3, \ldots, n$. Then
    \begin{align*}
      \mathrm{det} \begin{bmatrix}
        U + V\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
      = \mathrm{det} \begin{bmatrix}
        U\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
      + \mathrm{det} \begin{bmatrix}
        V\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
    \end{align*}
    For example, given that
    \begin{align*}
      \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 0
      \end{vmatrix} = -2
    \end{align*}
    We can compute
    \begin{align*}
      \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 5
      \end{vmatrix}\\
    \end{align*}
    using the row additive property.
    \begin{align*}
      [1, 0, 5] &= [1, 0, 0] + [0, 0, 5] \\
      \therefore
      \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 5
      \end{vmatrix}
      &= \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 0
      \end{vmatrix}
      + \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        0 & 0 & 5
      \end{vmatrix}
      = -2 + (1 \cdot 2 \cdot 5) = 8
    \end{align*}
  \item The determinant of an upper triangular matrix is the product of the entries on the main diagonal.
    \begin{align*}
      \begin{vmatrix}
        a & b & c\\
        0 & d & e\\
        0 & 0 & f
      \end{vmatrix}
      &= a(df - e \cdot 0) - b(0 \cdot f - e \cdot 0) + c(0 \cdot 0 - d \cdot 0) \\
      &= adf
    \end{align*}
\end{itemize}

\section{Reduction and Determinants}

\begin{itemize}
  \item Row Interchange Property states that the interchanging two rows must negate the value of the determinant.
    \begin{align*}
      \begin{bmatrix}
        1 & 2 & 3\\
        69 & 420 & 3232341\\
        1 & 2 & 3
      \end{bmatrix}
    \end{align*}
    Exchanging the row 1 and 3 must negate the value of the determinant.
    Zero is the only real number that equals its own negative.
    Thus, \textbf{any $n \times n$ matrix with two equal rows has a zero determinant}.
  \item \textbf{In any $n \times n$ matrix $A$, adding a multiple of one row of $A$ onto a different row does not change the determinant of $A$}.\\
    Suppose we get a matrix $B$ by adding a scalar multiple of the first row to the second.
    \begin{align*}
      \mathrm{det} B
      = \mathrm{det} \begin{bmatrix}
        A_1\\
        A_2 + c A_1\\
        \vdots\\
        A_n
      \end{bmatrix}
      = \mathrm{det} \begin{bmatrix}
        A_1\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
      = c \cdot \mathrm{det} \begin{bmatrix}
        A_1\\
        A_1\\
        \vdots\\
        A_n
      \end{bmatrix}
      = \mathrm{det} A + 0
      = \mathrm{det} A
    \end{align*}
  \item So far, we learned how elementary row operations affect the determinant.
    \begin{itemize}
      \item interchanging two rows: negates the determinant
      \item multiplying a row by a nonzero scalar: multiplies the determinant by the scalar
      \item adding a scalar multiple of a row to another: does not affect the determinant
    \end{itemize}
    We can use these properties to learn how to use row operations to calculate determinants.\\
    If we produce an echelon form matrix $R$ by applying row operations to a matrix $A$, the determinant of $A$ is
    \begin{align*}
      det(A) = \frac{\prod diag(R)}{d}
    \end{align*}
    where $d$ is the product of the scalars multiplied and $(-1)^{\text{number of rows swapped}}$.\\
    For example, to compute
    \begin{align*}
      &\begin{vmatrix}
        3 & 6 & 9 & 12\\
        1 & 2 & 2 & 1\\
        3 & 5 & 2 & 1\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      %
      \\
      &= 3 \cdot
      \arrows4{\frac{R_1}{3}}{}{}{}
      \begin{vmatrix}
        3 & 6 & 9 & 12\\
        1 & 2 & 2 & 1\\
        3 & 5 & 2 & 1\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      =
      3 \cdot
      \arrows4{}{R_2 - R_1}{R_3 - 3R_1}{}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & 0 & -1 & -3\\
        0 & -1 & -7 & -11\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      \\
      &=
      -3 \cdot
      \arrows4{}{R_3}{R_2}{}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & -1 & -7 & -11\\
        0 & 0 & -1 & -3\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      =
      -3 \cdot
      \arrows4{}{}{}{R_4 + 2R_2}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & -1 & -7 & -11\\
        0 & 0 & -1 & -3\\
        0 & 0 & -10 & -20
      \end{vmatrix}
      \\
      &=
      -3 \cdot
      \arrows4{}{}{}{R_4 - 10R_3}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & -1 & -7 & -11\\
        0 & 0 & -1 & -3\\
        0 & 0 & 0 & 10
      \end{vmatrix}
      \\
      &= -3 (1 \cdot -1 \cdot -1 \cdot 10) = -30
    \end{align*}
    We can even further simplify the process by only using he row operation number 3 (adding a scalar multiple of a row to another), though this totally will make the numbers messier.
    \begin{align*}
      \begin{vmatrix}
        2 & -3 & 1\\
        2 &  0 & 1\\
        1 & -4 & 5
      \end{vmatrix}
      &=
      \arrows4{}{R^2 - R^1}{R^3 - \frac{R^1}{2}}{}
      \begin{vmatrix}
        2 &           -3 &          1\\
        0 &            3 &          0\\
        0 & -\frac{5}{2} & \frac{9}{2}
      \end{vmatrix}
      \arrows4{}{}{R^3 - (3 \cdot - \frac{2}{5}) R^2}{}
      = \begin{vmatrix}
        2 & -3 &          1\\
        0 &  3 &          0\\
        0 &  0 & \frac{9}{2}
      \end{vmatrix} \\
      &\therefore det(A) = 2 \cdot 3 \cdot \frac{9}{2} = 27
    \end{align*}
  \item [Fun fact] The Laplace expansion recursively takes $O(n!)$ ($O(n^2)$ if sub-determinants are memoized), Gaussian elimination takes $O(n^3)$.
  \item An $n \times n$ matrix $A$ is invertible iff $\mathrm{det} A \neq 0$
\end{itemize}

\subsection{Uniqueness of the Determinant}

\begin{itemize}
  \item \textbf{Uniqueness Theorem}: Supposed thatt $D$ is a function that transforms $n \times n$ matrices into numbers such that
    \begin{enumerate}[label={(\alph*)}]
      \item $D(I) = I$
      \item $D$ satisfies the row interchange, the row scalar, and the row addirivity properties
    \end{enumerate}
    Then $D(A) = \mathrm{det} A$ for all $n \times n$ matrices $A$.
  \item \textbf{Product Theorem} states that for all $n \times n$ matrices $A$ and $B$, $\mathrm{det}(AB) = (\mathrm{det}(A))(\mathrm{det}(B))$.
  \item For any $n \times n$ matrix, $\mathrm{det} A = \mathrm{det} A^t$.
\end{itemize}

\subsection{Volume}

//TODO

\section{A Formula For Inverses}

\begin{itemize}
  \item \textbf{Cramer's Rule} states that if $A$ is invertible, then for $AX = Y$ where $X, Y \in \mathbb{R}^n$, $X = [ x_1, x_2, \ldots, x_n ]^t$ where
    \begin{align*}
      x_i = \frac{\mathrm{det} [ A_1, \ldots, A_{i - 1}, Y, A_{i + 1}, \ldots, A_n ]}{\mathrm{det} A}
    \end{align*}
    For example, to find the solution of
    \begin{align*}
      \begin{cases}
        5x_1 + 2x_2 + x_3 = y_1\\
        2x_1 + 2x_2 2x_3 = y_2\\
        2x_1 + x_2 + x_3 = y_3
      \end{cases}
    \end{align*}
    Find the determinant of the augmented matrix first
    \begin{align*}
      &
      \begin{vmatrix}
        5 & 2 & 1\\
        2 & 2 & 2\\
        2 & 1 & 1
      \end{vmatrix}
      =
      2
      \arrows3{}{\frac{R_2}{2}}{}
      \begin{vmatrix}
        5 & 2 & 1\\
        1 & 1 & 1\\
        2 & 1 & 1
      \end{vmatrix}
      =
      2
      \arrows3{R_1 - 5R_2}{}{R_3 - 2R_2}
      \begin{vmatrix}
        0 & -3 & -4\\
        1 & 1 & 1\\
        0 & -1 & -1
      \end{vmatrix}
      =
      - 2
      \arrows3{}{}{-R_3}
      \begin{vmatrix}
        0 & -3 & -4\\
        1 & 1 & 1\\
        0 & 1 & 1
      \end{vmatrix}
      \\
      &
      =
      -2
      \arrows3{R_1 + 3R_3}{R_2 - R_3}{}
      \begin{vmatrix}
        0 & 0 & -1\\
        1 & 0 & 0\\
        0 & 1 & 1
      \end{vmatrix}
      =
      2
      \arrows3{R_2}{R_1}{}
      \begin{vmatrix}
        1 & 0 & 0\\
        0 & 0 & -1\\
        0 & 1 & 1
      \end{vmatrix}
      =
      -2
      \arrows3{}{R_3}{R_2}
      \begin{vmatrix}
        1 & 0 & 0\\
        0 & 1 & 1\\
        0 & 0 & -1
      \end{vmatrix}
      = 2
    \end{align*}
    According to Cramer's rule,
    \begin{align*}
      &
      x_1 = \frac{\begin{vmatrix}
        y_1 & 2 & 1\\
        y_2 & 2 & 2\\
        y_3 & 1 & 1
      \end{vmatrix}}{2}
      = \frac{2y_1 + 4y_3 + y_2 - 2y_3 - 2y_2 - 2y_1}{2}
      = \frac{-y_2 + 2y_3}{2}
      %
      \\
      &
      x_2 = \frac{\begin{vmatrix}
        5 & y_1 & 1\\
        2 & y_2 & 2\\
        2 & y_3 & 1
      \end{vmatrix}}{2}
      = \frac{5y_2 + 4y_1 + 2y_3 - 2y_2 - 2y_1 - 10y_3}{2}
      = \frac{2y_1 + 3y_2 -8y_3}{2}
      %
      \\
      &
      x_3 = \frac{\begin{vmatrix}
        5 & 2 & y_1\\
        2 & 2 & y_2\\
        2 & 1 & y_3
      \end{vmatrix}}{2}
      = \frac{10y_3 + 4y_2 + 2y_1 - 4y_1 - 4y_3 - 5y_2}{2}
      = \frac{-2y_1 -y_2 + 6y_3}{2}
    \end{align*}
    \begin{align*}
      \therefore
      \begin{bmatrix}
        x_1\\ x_2\\ x_3
      \end{bmatrix}
      = \frac{1}{2} \begin{bmatrix}
        -y_2 + 2y_3\\
        2y_1 + 3y_2 - 8y_3\\
        -2y_1 - y_2 + 6y_3
      \end{bmatrix}
      = \frac{1}{2} \begin{bmatrix}
        0 & -1 & 2\\
        2 & 3 & -8\\
        -2 & -1 & 6
      \end{bmatrix} \begin{bmatrix}
        y_1\\ y_2\\ y_3
      \end{bmatrix}
    \end{align*}
    In fact, the matrix being multiplied to $Y$ is $A^{-1}$
  \item \textbf{Cramer's Rule for finding inverses}: Consider the elements of Laplace Expansion $(-1)^{i + j} a_{ij} A_{ij}$
    \begin{itemize}
      \item $A_{ij}$ is called a \textbf{minor} of the elemenet at $(i, j)$ and is the determinant of the smaller $(n - 1) \times (n - 1)$ sub-matrix resulting from deleting row $i$ and column $j$
      \item A \textbf{cofactor} $C_{ij} = (-1)^{i + j} A_{ij}$
      \item A \textbf{cofactor matrix} $C$ is the matrix of cofactors. For example for $A$
        \begin{align*}
          A &=
          \begin{bmatrix}
            a & b & c\\
            d & e & f\\
            g & h & i
          \end{bmatrix}\\
          C &=
          \begin{bmatrix}
            + \begin{vmatrix}
              e & f\\
              h & i
            \end{vmatrix}
          &- \begin{vmatrix}
            d & f\\
            g & i
          \end{vmatrix}
          &
          + \begin{vmatrix}
            d & e\\
            g & h
          \end{vmatrix}\\
          - \begin{vmatrix}
            b & c\\
            h & i
          \end{vmatrix}
          &
          + \begin{vmatrix}
            a & c\\
            g & i
          \end{vmatrix}
          &
          - \begin{vmatrix}
            a & b\\
            g & h
          \end{vmatrix}\\
          + \begin{vmatrix}
            b & c\\
            e & f
          \end{vmatrix}
          &
          - \begin{vmatrix}
            a & c\\
            d & f
          \end{vmatrix}
          &
          + \begin{vmatrix}
            a & b\\
            d & e
          \end{vmatrix}
            \end{bmatrix}
        \end{align*}
      \item An \textbf{adjugate} (or adjoint) is equal to $C^t$
        \begin{align*}
          C^t =
          \begin{pmatrix}
            + A_{11} & - A_{21} & + A_{31}\\
            - A_{12} & + A_{22} & - A_{32}\\
            + A_{13} & - A_{23} & + A_{33}\\
          \end{pmatrix}
        \end{align*}
    \end{itemize}
    Cramer's rule uses the adjugate to find the inverse, specifically,

    \begin{align*}
      A^{-1} = \frac{1}{\det A} C^t
    \end{align*}

    So, for

    \begin{align*}
      A
      &= \begin{bmatrix}
        2 & 0 & -1\\
        5 & 1 &  0 \\
        0 & 1 &  3
      \end{bmatrix}\\
      C^t &= \begin{bmatrix}
        + (3 - 0)  & - (0 + 1) & + (0 + 1)\\
        - (15 - 0) & + (6 + 0) & - (0 + 5) \\
        + (5 - 0)  & - (2 - 0) & + (2 - 0)
      \end{bmatrix}\\
      &= \begin{bmatrix}
        3 & -1 & 1\\
        -15 & 6 &  -5 \\
        5 & -2 &  2
      \end{bmatrix}
    \end{align*}

    We already found that $\det A = 1$, so $A^{-1} = \frac{1}{1} C^t = C^t$.
\end{itemize}
