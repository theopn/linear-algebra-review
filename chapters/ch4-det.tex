%! TEX root = ../ma351.tex

\section{Definition of the Determinant}

\begin{itemize}
  \item For a $2 \times 2$ matrix,
    \begin{align*}
      \begin{bmatrix}
        a & b\\
        c & d
      \end{bmatrix}^{-1} = \frac{1}{ad - cb}
      \begin{bmatrix}
        d & -b\\
        -c & a
      \end{bmatrix}
    \end{align*}
    The factor $\delta = ad - cb$ is called \textbf{determinant}.
    \begin{align*}
      det \begin{bmatrix}
        a & b\\
        c & d
      \end{bmatrix} = \begin{vmatrix}
        a & b\\
        c & d
      \end{vmatrix} = ad - bc
    \end{align*}
  \item \textbf{Laplace Expansion} or \textbf{Cofactor Expansion} states that the determinant of any $n \times n$ matrix can be obtained using using determinants of $(n - 1) \times (n - 1)$ submatrices.
    Specifically, for every $i$,
    \begin{align*}
      det(A) &= \sum_{j=1}^{n} (-1)^{i + j} a_{ij} A_{ij}
    \end{align*}
    \noindent Where $a_{ij}$ is the entry of $i$th row and $j$th column and $A_{ij}$ is the determinant of the submatrix obtained by removing the $i$th row and $j$th column.
  \item We can use Laplace Expansion to find the determinant of $3 \times 3$ matrix. Choosing $i = 1$,
    \begin{align*}
      \begin{vmatrix}
        a & b & c\\
        d & e & f\\
        g & h & i
      \end{vmatrix}
      &=
      a \cdot \begin{vmatrix}
        \text{\sout{a}} & \text{\sout{b}} & \text{\sout{c}}\\
        \text{\sout{d}} & e & f\\
        \text{\sout{g}} & h & i
      \end{vmatrix}
      - b \cdot \begin{vmatrix}
        \text{\sout{a}} & \text{\sout{b}} & \text{\sout{c}}\\
        d & \text{\sout{e}} & f\\
        g & \text{\sout{h}} & i
      \end{vmatrix}
      + c \cdot \begin{vmatrix}
        \text{\sout{a}} & \text{\sout{b}} & \text{\sout{c}}\\
        d & e & \text{\sout{f}}\\
        g & h & \text{\sout{i}}
      \end{vmatrix}\\
      &= a(ei - fh) - b(di - fg) + c(dh - eg)\\
      &= aei + bfg + cdh - ceg - bdi - afh
    \end{align*}
    Choosing $i = 2$ yields the same result
    \begin{align*}
      \begin{vmatrix}
        a & b & c\\
        d & e & f\\
        g & h & i
      \end{vmatrix}
      &=
      - d \cdot \begin{vmatrix}
        \text{\sout{a}} & b & c\\
        \text{\sout{d}} & \text{\sout{e}} & \text{\sout{f}}\\
        \text{\sout{g}} & h & i
      \end{vmatrix}
      + e \cdot \begin{vmatrix}
        a & \text{\sout{b}} & c\\
        \text{\sout{d}} & \text{\sout{e}} & \text{\sout{f}}\\
        g & \text{\sout{h}} & i
      \end{vmatrix}
      - f \cdot \begin{vmatrix}
        a & b & \text{\sout{c}}\\
        \text{\sout{d}} & \text{\sout{e}} & \text{\sout{f}}\\
        g & h & \text{\sout{i}}
      \end{vmatrix}\\
      &= -d(bi - ch) + e(ai - cg) - f(ah - bg)\\
      &= -bdi + cdh + aei - ceg - afh + bfg\\
      &= aei + bfg + cdh - ceg - bdi - afh
    \end{align*}
    Focus on the signs since the values of $(-1)^{i + j}$ differ when we chose to fix $i = 1$ versus $i = 2$.\\
    Also, you can change the $i$ and $j$ in the summation and the equation still holds since the determinants of $A$ and $A^{t}$ are identical.
  \item \textbf{Row Interchange Property}: Let $A$ be an $n \times n$ matrix and supposed $B$ is obtained by interchanging two rows of $A$.
    Then $\mathrm{det} B = - \mathrm{det} A$
  \item \textbf{Row Scalar Property}: Supposed the $n \times n$ matrix $B$ is obtained from $A$ by multiplying each element in the $i$th row by some scalar $c$.
    Then $\mathrm{det} B = c \mathrm{det} A$
  \item \textbf{Row Additive Property}: Let $U$, $V$, and $A_i$ be $1 \times n$ row matrices, where $i = 2, 3, \ldots, n$. Then
    \begin{align*}
      \mathrm{det} \begin{bmatrix}
        U + V\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
      = \mathrm{det} \begin{bmatrix}
        U\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
      + \mathrm{det} \begin{bmatrix}
        V\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
    \end{align*}
    For example, given that
    \begin{align*}
      \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 0
      \end{vmatrix} = -2
    \end{align*}
    We can compute
    \begin{align*}
      \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 5
      \end{vmatrix}\\
    \end{align*}
    using the row additive property.
    \begin{align*}
      [1, 0, 5] &= [1, 0, 0] + [0, 0, 5] \\
      \therefore
      \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 5
      \end{vmatrix}
      &= \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        1 & 0 & 0
      \end{vmatrix}
      + \begin{vmatrix}
        1 & 2 & 3\\
        0 & 2 & 2\\
        0 & 0 & 5
      \end{vmatrix}
      = -2 + (1 \cdot 2 \cdot 5) = 8
    \end{align*}
  \item The determinant of an upper triangular matrix is the product of the entries on the main diagonal.
    \begin{align*}
      \begin{vmatrix}
        a & b & c\\
        0 & d & e\\
        0 & 0 & f
      \end{vmatrix}
      &= a(df - e \cdot 0) - b(0 \cdot f - e \cdot 0) + c(0 \cdot 0 - d \cdot 0) \\
      &= adf
    \end{align*}
\end{itemize}

\section{Reduction and Determinants}

\begin{itemize}
  \item Row Interchange Property states that the interchanging two rows must negate the value of the determinant.
    \begin{align*}
      \begin{bmatrix}
        1 & 2 & 3\\
        69 & 420 & 3232341\\
        1 & 2 & 3
      \end{bmatrix}
    \end{align*}
    Exchanging the row 1 and 3 must negate the value of the determinant.
    Zero is the only real number that equals its own negative.
    Thus, \textbf{any $n \times n$ matrix with two equal rows has a zero determinant}.
  \item \textbf{In any $n \times n$ matrix $A$, adding a multiple of one row of $A$ onto a different row does not change the determinant of $A$}.\\
    Suppose we get a matrix $B$ by adding a scalar multiple of the first row to the second.
    \begin{align*}
      \mathrm{det} B
      = \mathrm{det} \begin{bmatrix}
        A_1\\
        A_2 + c A_1\\
        \vdots\\
        A_n
      \end{bmatrix}
      = \mathrm{det} \begin{bmatrix}
        A_1\\
        A_2\\
        \vdots\\
        A_n
      \end{bmatrix}
      = c \cdot \mathrm{det} \begin{bmatrix}
        A_1\\
        A_1\\
        \vdots\\
        A_n
      \end{bmatrix}
      = \mathrm{det} A + 0
      = \mathrm{det} A
    \end{align*}
  \item So far, we learned how elementary row operations affect the determinant.
    \begin{itemize}
      \item interchanging two rows: negates the determinant
      \item multiplying a row by a nonzero scalar: multiplies the determinant by the scalar
      \item adding a scalar multiple of a row to another: does not affect the determinant
    \end{itemize}
    We can use these properties to learn how to use row operations to calculate determinants.\\
    If we produce an echelon form matrix $R$ by applying row operations to a matrix $A$, the determinant of $A$ is
    \begin{align*}
      det(A) = \frac{\prod diag(R)}{d}
    \end{align*}
    where $d$ is the product of the scalars multiplied and $(-1)^{\text{number of rows swapped}}$.\\
    For example, to compute
    \begin{align*}
      &\begin{vmatrix}
        3 & 6 & 9 & 12\\
        1 & 2 & 2 & 1\\
        3 & 5 & 2 & 1\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      %
      \\
      &= 3 \cdot
      \arrows4{3R_1}{}{}{}
      \begin{vmatrix}
        3 & 6 & 9 & 12\\
        1 & 2 & 2 & 1\\
        3 & 5 & 2 & 1\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      =
      3 \cdot
      \arrows4{}{R_2 - R_1}{R_3 - 3R_1}{}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & 0 & -1 & -3\\
        0 & -1 & -7 & -11\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      \\
      &=
      -3 \cdot
      \arrows4{}{R_3}{R_2}{}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & -1 & -7 & -11\\
        0 & 0 & -1 & -3\\
        0 & 2 & 4 & 2
      \end{vmatrix}
      =
      -3 \cdot
      \arrows4{}{}{}{R_4 + 2R_2}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & -1 & -7 & -11\\
        0 & 0 & -1 & -3\\
        0 & 0 & -10 & -20
      \end{vmatrix}
      \\
      &=
      -3 \cdot
      \arrows4{}{}{}{R_4 - 10R_3}
      \begin{vmatrix}
        1 & 2 & 3 & 4\\
        0 & -1 & -7 & -11\\
        0 & 0 & -1 & -3\\
        0 & 0 & 0 & 10
      \end{vmatrix}
      \\
      &= -3 (1 \cdot -1 \cdot -1 \cdot 10) = -30
    \end{align*}
    We can even further simplify the process by only using he row operation number 3 (adding a scalar multiple of a row to another), though this totally will make the numbers messier.
    \begin{align*}
      \begin{vmatrix}
        2 & -3 & 1\\
        2 &  0 & 1\\
        1 & -4 & 5
      \end{vmatrix}
      &=
      \arrows4{}{R^2 - R^1}{R^3 - \frac{R^1}{2}}{}
      \begin{vmatrix}
        2 &           -3 &          1\\
        0 &            3 &          0\\
        0 & -\frac{5}{2} & \frac{9}{2}
      \end{vmatrix}
      \arrows4{}{}{R^3 - (3 \cdot - \frac{2}{5}) R^2}{}
      = \begin{vmatrix}
        2 & -3 &          1\\
        0 &  3 &          0\\
        0 &  0 & \frac{9}{2}
      \end{vmatrix} \\
      &\therefore det(A) = 2 \cdot 3 \cdot \frac{9}{2} = 27
    \end{align*}
  \item [Fun fact] The Laplace expansion recursively takes $O(n!)$ ($O(n^2)$ if sub-determinants are memoized), Gaussian elimination takes $O(n^3)$.
  \item An $n \times n$ matrix $A$ is invertible iff $\mathrm{det} A \neq 0$
\end{itemize}

\subsection{Uniqueness of the Determinant}

\begin{itemize}
  \item \textbf{Uniqueness Theorem}: Supposed thatt $D$ is a function that transforms $n \times n$ matrices into numbers such that
    \begin{enumerate}[label={(\alph*)}]
      \item $D(I) = I$
      \item $D$ satisfies the row interchange, the row scalar, and the row addirivity properties
    \end{enumerate}
    Then $D(A) = \mathrm{det} A$ for all $n \times n$ matrices $A$.
  \item \textbf{Product Theorem} states that for all $n \times n$ matrices $A$ and $B$, $\mathrm{det}(AB) = (\mathrm{det}(A))(\mathrm{det}(B))$.
  \item For any $n \times n$ matrix, $\mathrm{det} A = \mathrm{det} A^t$.
\end{itemize}

\subsection{Volume}

//TODO

\section{A Formula For Inverses}

\begin{itemize}
  \item \textbf{Cramer's Rule} Consider the elements of Laplace Expansion $(-1)^{i + j} a_{ij} A_{ij}$
    \begin{itemize}
      \item $A_{ij}$ is called a \textbf{minor} of the elemenet at $(i, j)$ and is the determinant of the smaller $(n - 1) \times (n - 1)$ sub-matrix resulting from deleting row $i$ and column $j$
      \item A \textbf{cofactor} $C_{ij} = (-1)^{i + j} A_{ij}$
      \item A \textbf{cofactor matrix} $C$ is the matrix of cofactors. For example for $A$
        \begin{align*}
          A &=
          \begin{bmatrix}
            a & b & c\\
            d & e & f\\
            g & h & i
          \end{bmatrix}\\
          C &=
          \begin{bmatrix}
            + \begin{vmatrix}
              e & f\\
              h & i
            \end{vmatrix}
          &- \begin{vmatrix}
            d & f\\
            g & i
          \end{vmatrix}
          &
          + \begin{vmatrix}
            d & e\\
            g & h
          \end{vmatrix}\\
          - \begin{vmatrix}
            b & c\\
            h & i
          \end{vmatrix}
          &
          + \begin{vmatrix}
            a & c\\
            g & i
          \end{vmatrix}
          &
          - \begin{vmatrix}
            a & b\\
            g & h
          \end{vmatrix}\\
          + \begin{vmatrix}
            b & c\\
            e & f
          \end{vmatrix}
          &
          - \begin{vmatrix}
            a & c\\
            d & f
          \end{vmatrix}
          &
          + \begin{vmatrix}
            a & b\\
            d & e
          \end{vmatrix}
            \end{bmatrix}
        \end{align*}
      \item An \textbf{adjugate} (or adjoint) is equal to $C^t$
        \begin{align*}
          C^t =
          \begin{pmatrix}
            + A_{11} & - A_{21} & + A_{31}\\
            - A_{12} & + A_{22} & - A_{32}\\
            + A_{13} & - A_{23} & + A_{33}\\
          \end{pmatrix}
        \end{align*}
    \end{itemize}
    Cramer's rule uses the adjugate to find the inverse, specifically,

    \begin{align*}
      A^{-1} = \frac{1}{\det A} C^t
    \end{align*}

    So, for

    \begin{align*}
      A
      &= \begin{bmatrix}
        2 & 0 & -1\\
        5 & 1 &  0 \\
        0 & 1 &  3
      \end{bmatrix}\\
      C^t &= \begin{bmatrix}
        + (3 - 0)  & - (0 + 1) & + (0 + 1)\\
        - (15 - 0) & + (6 + 0) & - (0 + 5) \\
        + (5 - 0)  & - (2 - 0) & + (2 - 0)
      \end{bmatrix}\\
      &= \begin{bmatrix}
        3 & -1 & 1\\
        -15 & 6 &  -5 \\
        5 & -2 &  2
      \end{bmatrix}
    \end{align*}

    We already found that $\det A = 1$, so $A^{-1} = \frac{1}{1} C^t = C^t$.
  \item To use Cramer's rule to solve the system,  TODO: page 264
\end{itemize}

\section{Checking Invertibility of a Matrix}

Following statements are equivalent for an $n \times n$ matrix $A$.

\begin{itemize}
  \item $A$ is invertible (or nonsingular), i.e., there exists a matrix $B$ such that $AB = I_n = BA$
  \item $\rank A = n$
  \item $A$ is row equivalent to $I_n$
  \item The dimensions of both row space and column space of $A$ are $n$
  \item The nullspace (kernel) of $A$ is $\{0\}$
  \item $\forall B \in \mathbb{R}^n$, $AX = B$ has exactly one solution
  \item $\determinant A \neq 0$
\end{itemize}

Let us invert $A$ where

\begin{align*}
  A =
  \begin{pmatrix}
    2 & 0 & -1\\
    5 & 1 &  0 \\
    0 & 1 &  3
  \end{pmatrix}
\end{align*}

To verify the Invertibility of $A$, we can check its determinant.

\begin{align*}
  \begin{pmatrix}
    2 & 0 & -1\\
    5 & 1 &  0 \\
    0 & 1 &  3
  \end{pmatrix}
  \begin{pmatrix}
    2 & 0 &           -1\\
    0 & 1 & \frac{5}{2} \\
    0 & 1 &           3
  \end{pmatrix}
  \explain{$R_2 \rightarrow R_2 - \frac{5}{2} R_1$}
  \begin{pmatrix}
    2 & 0 &           -1\\
    0 & 1 & \frac{5}{2} \\
    0 & 0 & \frac{1}{2}
  \end{pmatrix}
  \explain{$R_3 \rightarrow R_3 - R_2$}\\
  \therefore \det A = 2 \cdot 1 \cdot \frac{1}{2} = 1
\end{align*}

Thus, $A$ is invertible.

\section{Using Row Operations to Invert a Matrix}

We can reduce $[A | I]$ until it becomes $[I | A^{-1}]$ to find the inverse.
By the way, did you know that $I = [\delta_{ij}]$ where $\delta_{ij}$ is the Kronecker delta defined by

\begin{align*}
  \delta_{ij} =
  \begin{cases}
    0 & \quad i \neq j\\
    1 & \quad i = j
  \end{cases}
\end{align*}

Anyway, reducing $[A | I]$,

\begin{align*}
  \left(
    \begin{array}{rrr|rrr}  % r for right, c for center
      2 & 0 & -1 & 1 & 0 & 0\\
      5 & 1 &  0 & 0 & 1 & 0\\
      0 & 1 &  3 & 0 & 0 & 1
    \end{array}
  \right)\\
  \left(
    \begin{array}{rrr|rrr}
      1 & 0 & - \frac{1}{2} & \frac{1}{2} & 0 & 0\\
      5 & 1 &             0 &           0 & 1 & 0\\
      0 & 1 &             3 &           0 & 0 & 1
    \end{array}
  \right)
  \explain{$R_1 \rightarrow \frac{R_1}{2}$}\\
  \left(
    \begin{array}{rrr|rrr}
      1 & 0 & - \frac{1}{2} &  \frac{1}{2} & 0 & 0\\
      0 & 1 &   \frac{5}{2} & -\frac{5}{2} & 1 & 0\\
      0 & 1 &             3 &            0 & 0 & 1
    \end{array}
  \right)
  \explain{$R_2 \rightarrow R_2 - 5R_1$}\\
  \left(
    \begin{array}{rrr|rrr}
      1 & 0 & - \frac{1}{2} &  \frac{1}{2} &  0 & 0\\
      0 & 1 &   \frac{5}{2} & -\frac{5}{2} &  1 & 0\\
      0 & 0 &   \frac{1}{2} &  \frac{5}{2} & -1 & 1
    \end{array}
  \right)
  \explain{$R_3 \rightarrow R_3 - R_2$}\\
  \left(
    \begin{array}{rrr|rrr}
      1 & 0 &             0 &            3 & -1 &  1\\
      0 & 1 &             0 &          -15 &  6 & -5\\
      0 & 0 &   \frac{1}{2} &  \frac{5}{2} & -1 &  1
    \end{array}
  \right)
  \explain{{$R_1 \rightarrow R_1 + R_3$}\\{$R_2 \rightarrow R_2 - 5R_3$}}\\
  \left(
    \begin{array}{rrr|rrr}
      1 & 0 & 0 &   3 & -1 &  1\\
      0 & 1 & 0 & -15 &  6 & -5\\
      0 & 0 & 1 &   5 & -2 &  2
    \end{array}
  \right)
  \explain{$R_3 \rightarrow 2R_3$}
\end{align*}

Thus,

\begin{align*}
  A^{-1} =
  \begin{pmatrix}
    3 & -1 & 1\\
    -15 & 6 & -5\\
    5 & -2 & 2
  \end{pmatrix}
\end{align*}

And indeed, $AA^{-1} = I$.

\section{Using Cramer's Rule to Invert a Matrix}


